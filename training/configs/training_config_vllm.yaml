# Training Configuration for vLLM Integration
# This configuration file is specifically for vLLM inference integration
# Does NOT affect the existing training configs

# Model configuration
model:
  name: "Qwen/Qwen2.5-0.5B-Instruct"
  use_lora: true
  value_head_hidden_dim: 1024

# Data paths (same as original)
data_path: "data/inputs/train.json"
validation_data_path: "data/inputs/validation.json"
output_dir: "./outputs/qwen3-vllm-grpo"

# Training hyperparameters
num_epochs: 3
batch_size: 1
learning_rate: 5e-5
weight_decay: 0.01
warmup_steps: 100
gradient_accumulation_steps: 4

# LoRA mode settings (for single GPU)
lora_mode:
  per_device_train_batch_size: 2
  gradient_checkpointing: false  # DISABLED: Incompatible with Qwen2 KV caching
  fp16: true
  
# Full fine-tuning mode settings
full_finetune_mode:
  per_device_train_batch_size: 1
  gradient_checkpointing: false  # DISABLED: Incompatible with Qwen2 KV caching
  bf16: true
  deepspeed_config: "./configs/deepspeed_config.json"

# Optimizer settings
optimizer:
  type: "adamw_torch"
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_epsilon: 1e-8

# Learning rate scheduler
lr_scheduler:
  type: "cosine"
  warmup_ratio: 0.1

# Evaluation settings
eval_steps: 50
eval_batch_size: 4
save_steps: 100
save_total_limit: 3
load_best_model_at_end: true
metric_for_best_model: "eval_success_rate"
greater_is_better: true

# Early stopping
early_stopping:
  enabled: true
  patience: 5
  threshold: 0.001

# Logging configuration
logging:
  logging_steps: 10
  logging_first_step: true
  report_to: ["wandb", "weave"]
  wandb_project: "skyrl-qwen3-vllm"
  weave_project: "synergia_Agents/skyrl-qwen3-vllm"
  
# Curriculum learning settings
curriculum_learning:
  enabled: true
  warmup_epochs: 1
  difficulty_schedule: "linear"
  min_complexity: "easy"
  max_complexity: "hard"
  
# Data loader settings
cache_size: 1000
num_workers: 4
shuffle: true
seed: 42

# Device settings
device_config:
  use_mps: false
  use_cuda: true
  device_map: "auto"
  
# Memory optimization
memory_optimization:
  gradient_checkpointing: false  # DISABLED: Incompatible with Qwen2 KV caching
  clear_cache_steps: 100
  max_memory_mb: 16000