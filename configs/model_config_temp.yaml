device_map: null
generation:
  do_sample: true
  eos_token_id: 151645
  max_new_tokens: 512
  pad_token_id: 151643
  repetition_penalty: 1.1
  temperature: 0.7
  top_k: 50
  top_p: 0.9
lora_mode:
  alpha: 32
  bias: none
  dropout: 0.1
  enabled: true
  fan_in_fan_out: false
  init_lora_weights: true
  r: 16
  target_modules:
  - q_proj
  - k_proj
  - v_proj
  - o_proj
  - gate_proj
  - up_proj
  - down_proj
max_length: 1024
memory_optimization:
  device_map: null
  load_in_4bit: false
  load_in_8bit: false
  low_cpu_mem_usage: true
  torch_dtype: float32
  trust_remote_code: true
model_name: Qwen/Qwen2.5-0.5B-Instruct
quantization:
  bnb_4bit_compute_dtype: float16
  bnb_4bit_quant_type: nf4
  bnb_4bit_use_double_quant: true
stop_sequences:
- <|im_end|>
tokenizer_name: Qwen/Qwen2.5-0.5B-Instruct
torch_dtype: float32
trust_remote_code: true
