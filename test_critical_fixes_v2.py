#!/usr/bin/env python3
"""
Test Critical Training Fixes V2
===============================

Tests the 6 critical fixes implemented based on detailed analysis:
1. ‚úÖ Tool call parsing and argument aliasing
2. ‚úÖ Improved prompting to generate tool calls immediately  
3. ‚úÖ Optimized generation parameters (temperature, max_tokens, stop sequences)
4. ‚úÖ Fixed reference policy sync to exclude BnB buffers
5. ‚úÖ Fixed WandB metrics logging to always log rollout metrics
6. üîß Fixed empty tensor crash in GRPO trainer (to be implemented by user)

This tests the tool parsing and argument normalization fix specifically.
"""

import json
import sys
import os
from pathlib import Path

# Add necessary paths
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))
sys.path.insert(0, str(current_dir / "environments"))
sys.path.insert(0, str(current_dir / "training"))
sys.path.insert(0, str(current_dir / "training" / "core"))

# Set environment variables
os.environ['PYTHONPATH'] = f"{current_dir}:{current_dir / 'environments'}:{current_dir / 'training'}"

def test_tool_call_normalization():
    """Test the argument aliasing fix by checking the source code"""
    
    print("üß™ TESTING TOOL CALL ARGUMENT NORMALIZATION")
    print("=" * 60)
    
    # Check if the normalization method exists in the source file
    env_file = current_dir / "environments" / "mcp_tool_environment.py"
    
    if not env_file.exists():
        print("‚ùå Environment file not found")
        return False
    
    with open(env_file, 'r') as f:
        content = f.read()
    
    # Check for key components of our fix
    checks = [
        ("Normalization method exists", "_normalize_tool_call_args" in content),
        ("Normalization is called", "self._normalize_tool_call_args(tool_call)" in content),
        ("execute_python alias mapping", '"python_code": "code"' in content),
        ("tavily_search alias mapping", '"search_query": "query"' in content),
        ("fmp_get_quote alias mapping", '"ticker": "symbol"' in content),
        ("send_slack_message alias mapping", '"msg": "message"' in content)
    ]
    
    all_passed = True
    for description, check in checks:
        status = "‚úÖ PASSED" if check else "‚ùå FAILED"
        print(f"   {status}: {description}")
        if not check:
            all_passed = False
    
    return all_passed

def test_prompt_improvements():
    """Test the improved prompting system by checking source code"""
    
    print("\nüß™ TESTING PROMPT IMPROVEMENTS")
    print("=" * 60)
    
    # Check the source file directly
    policy_file = current_dir / "training" / "core" / "qwen_policy_with_prompting.py"
    
    if not policy_file.exists():
        print("‚ùå Policy file not found")
        return False
    
    with open(policy_file, 'r') as f:
        content = f.read()
    
    # Extract the prompt
    prompt_start = content.find('TOOL_CALLING_PROMPT = """') + len('TOOL_CALLING_PROMPT = """')
    prompt_end = content.find('"""', prompt_start)
    prompt = content[prompt_start:prompt_end] if prompt_start > 0 and prompt_end > 0 else ""
    
    print(f"Current prompt: {prompt}")
    
    # Check key improvements
    checks = [
        ("More direct instruction", "RESPOND ONLY WITH A TOOL CALL" in prompt),
        ("Immediate tool call instruction", "START YOUR RESPONSE WITH <tool_call>" in prompt),
        ("Shorter and more focused", len(prompt) < 500),
        ("No <think> encouragement", "<think>" not in prompt),
        ("Prompt exists", len(prompt) > 0)
    ]
    
    all_passed = True
    for description, check in checks:
        status = "‚úÖ PASSED" if check else "‚ùå FAILED"
        print(f"   {status}: {description}")
        if not check:
            all_passed = False
    
    return all_passed

def test_generation_config():
    """Test the improved generation configuration"""
    
    print("\nüß™ TESTING GENERATION CONFIG IMPROVEMENTS")
    print("=" * 60)
    
    # Read the config file
    config_path = Path(__file__).parent / "training" / "configs" / "model_config_qwen3_0.6b.yaml"
    
    if not config_path.exists():
        print("‚ùå Config file not found")
        return False
    
    import yaml
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    gen_config = config.get('generation', {})
    stop_seqs = config.get('stop_sequences', [])
    
    # Check improvements
    checks = [
        ("Lower temperature for focused generation", gen_config.get('temperature', 1.0) < 0.5),
        ("Shorter max_tokens for tool calls", gen_config.get('max_new_tokens', 2048) <= 512),
        ("Additional stop sequences", len(stop_seqs) >= 6),
        ("Repetition penalty added", 'repetition_penalty' in gen_config)
    ]
    
    all_passed = True
    for description, check in checks:
        status = "‚úÖ PASSED" if check else "‚ùå FAILED"
        print(f"   {status}: {description}")
        if not check:
            all_passed = False
    
    print(f"\n   Current generation config: {gen_config}")
    print(f"   Stop sequences: {stop_seqs}")
    
    return all_passed

def main():
    """Run all tests"""
    
    print("üîß TESTING CRITICAL TRAINING FIXES V2")
    print("=" * 80)
    
    tests = [
        ("Tool Call Normalization", test_tool_call_normalization),
        ("Prompt Improvements", test_prompt_improvements), 
        ("Generation Config", test_generation_config)
    ]
    
    all_passed = True
    results = []
    
    for test_name, test_func in tests:
        try:
            passed = test_func()
            results.append((test_name, passed))
            if not passed:
                all_passed = False
        except Exception as e:
            print(f"\n‚ùå ERROR in {test_name}: {e}")
            results.append((test_name, False))
            all_passed = False
    
    # Summary
    print("\n" + "=" * 80)
    print("üèÜ TEST RESULTS SUMMARY")
    print("=" * 80)
    
    for test_name, passed in results:
        status = "‚úÖ PASSED" if passed else "‚ùå FAILED"
        print(f"   {status}: {test_name}")
    
    print(f"\nüéØ OVERALL: {'‚úÖ ALL TESTS PASSED' if all_passed else '‚ùå SOME TESTS FAILED'}")
    
    if all_passed:
        print("\nüöÄ Ready to test training! The critical fixes should resolve:")
        print("   - No more 'No tool calls found' issues")
        print("   - Model will generate tool calls immediately") 
        print("   - Better argument parsing with aliases")
        print("   - WandB rollout metrics will always appear")
        print("   - No more BnB buffer sync warnings")
    else:
        print("\nüîß Some fixes need attention before training")
    
    return 0 if all_passed else 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)